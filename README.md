With the rapid advancement of humanâ€“computer interaction (HCI), touchless control systems are becoming increasingly important in modern computing environments. Gesture-based interfaces allow users to interact with systems without physical contact, improving accessibility, hygiene, and convenience. 

This project presents a real-time hand gesture recognition system capable of controlling media playback and system volume using computer vision and machine learning. The system uses a webcam to detect hand gestures and maps them to actions such as play/pause, volume control, and mute. 

The solution is designed to be lightweight, cross-platform, and responsive, making it suitable for smart environments, accessibility tools, and future AR/VR interfaces. 
The main objectives of this project are: 

Develop a real-time hand gesture recognition system 

Use machine learning for gesture classification 

Implement cross-platform media and volume control 

Ensure low latency and smooth user interaction 

Build an optimized and user-friendly interface 

Demonstrate practical AI + embedded interaction use case 
